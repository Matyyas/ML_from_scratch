{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_boston, load_digits, load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import clone\n",
    "from itertools import compress\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement Adaboost SAMME regarding R.Schapire paper.\n",
    "\n",
    "We will try to comment the code step by step, so the reader can learn both concept and code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost_SAMME():\n",
    "    \"\"\" Homemade AdaBoost SAMME classifier class \"\"\"\n",
    "   \n",
    "    alpha = []\n",
    "    H = []\n",
    "    \n",
    "    def __init__(self, base_estimator, n_estimators, K):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.K = K\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n = len(X)\n",
    "        weights = np.ones(n)/n\n",
    "        self.alpha = []\n",
    "        self.H = []\n",
    "        \n",
    "        for m in range(0, self.n_estimators):\n",
    "            \n",
    "            # fit base estimator on the weighted distribution\n",
    "            h_m = self.base_estimator.fit(X, y, sample_weight=weights)\n",
    "            h_m_preds = h_m.predict(X)\n",
    "            \n",
    "            # List of weighted classifiers\n",
    "            self.H.append(clone(h_m).fit(X, y, sample_weight=weights))\n",
    "            \n",
    "            # Calculate the weighted error\n",
    "            err = np.isclose(y, h_m_preds)\n",
    "            indicatrice_error = [not c for c in err]            \n",
    "            error_m = np.sum(list(compress(weights, indicatrice_error))) / np.sum(weights)\n",
    "            \n",
    "            # Calculate alpha_m -> the less error the bigger alpha\n",
    "            alpha_m = np.log((1 - error_m) / error_m) + np.log(self.K - 1)\n",
    "            self.alpha.append(alpha_m)\n",
    "                         \n",
    "            # Update the weights for the next iteration : the mispredicted observations are given a bigger weight\n",
    "            indicatrice_vector = np.multiply(indicatrice_error, 1)\n",
    "            weights = np.multiply(weights, np.exp(alpha_m * indicatrice_vector))\n",
    "            \n",
    "            # Renormalize the weights\n",
    "            weights = weights / np.sum(weights)       \n",
    "        \n",
    "        return \n",
    "    \n",
    "\n",
    "    def predict(self, X_new):\n",
    "        y_new = []        \n",
    "        new_preds = []\n",
    "        \n",
    "        # Predict the output of the new X given the M estimators previously fited \n",
    "        for m in range(0, len(self.H)):\n",
    "            new_preds.append(self.H[m].predict(X_new))\n",
    "        \n",
    "        # Compute the matrix of weighted class predictions\n",
    "        final_pred = []\n",
    "        for i in range(0, len(X_new)):                        \n",
    "            class_pred = []\n",
    "            for k in range(0, self.K):              \n",
    "                somme = 0\n",
    "                for m in range(0, len(self.H)):                    \n",
    "                        if new_preds[m][i]==k:\n",
    "                            somme += self.alpha[m]                \n",
    "                class_pred.append(somme)\n",
    "            final_pred.append(class_pred)\n",
    "        \n",
    "        # Select the max weighted class prediction\n",
    "        for i in range(0, len(final_pred)):\n",
    "            y_new.append(np.argmax(final_pred[i]))\n",
    "            \n",
    "        return y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaison of our homemade Adaboost to sklearn Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST data\n",
    "digits = load_digits()\n",
    "X_digits = digits['data']\n",
    "y_digits = digits['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of our homemade Adaboost classifier :  0.98\n"
     ]
    }
   ],
   "source": [
    "# Building train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits, test_size=0.25)\n",
    "\n",
    "# Fit and predict of homemade Adaboost\n",
    "ada_homemade = AdaBoost_SAMME(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
    "                              n_estimators=50, K=len(digits.target_names))\n",
    "ada_homemade.fit(X_train, y_train)\n",
    "print(\"Accuracy score of our homemade Adaboost classifier : \", accuracy_score(y_test, ada_homemade.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of sklearn Adaboost classifier :  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict of sklearn Adaboost \n",
    "ada_sklearn = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=5)\n",
    "                                  , n_estimators=50, algorithm='SAMME') \n",
    "ada_sklearn.fit(X_train, y_train)\n",
    "print(\"Accuracy score of sklearn Adaboost classifier : \", accuracy_score(y_test, ada_sklearn.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
